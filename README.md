# Zonemaker AI - AI ê¸°ë°˜ ìœˆë„ìš° ë°°ì—´ ìµœì í™” ì‹œìŠ¤í…œ

## ğŸ“– ê°œìš”

Zonemaker AIëŠ” Microsoft Copilot PCì˜ Snapdragon NPUë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ìœˆë„ìš° ì‚¬ìš© íŒ¨í„´ì„ í•™ìŠµí•˜ê³ , ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì ì˜ ìœˆë„ìš° ë°°ì—´ì„ ì œì•ˆí•˜ëŠ” AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤. Vision Transformer ê¸°ë°˜ì˜ ê²½ëŸ‰í™”ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ ë¹ ë¥¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

- **ì‹¤ì‹œê°„ ìœˆë„ìš° ëª¨ë‹ˆí„°ë§**: Windows APIë¥¼ í†µí•œ ì§€ì†ì ì¸ ìœˆë„ìš° ìƒíƒœ ì¶”ì 
- **AI ê¸°ë°˜ ë°°ì—´ ì˜ˆì¸¡**: 30ì´ˆ ê´€ì°° í›„ ë‹¤ìŒ ìˆœê°„ì˜ ìœˆë„ìš° ìœ„ì¹˜ ì˜ˆì¸¡
- **ì—°ì† ìµœì í™”**: 1ì´ˆë§ˆë‹¤ ìƒˆë¡œìš´ ì˜ˆì¸¡ìœ¼ë¡œ ì§€ì†ì ì¸ ìµœì í™”
- **NPU ìµœì í™”**: Snapdragon NPU ì „ìš© ëª¨ë¸ ë³€í™˜ ë° ìµœì í™”
- **ì§ê´€ì  UI**: PySide6 ê¸°ë°˜ì˜ ì‚¬ìš©ì ì¹œí™”ì  ì¸í„°í˜ì´ìŠ¤
- **RESTful API**: FastAPI ê¸°ë°˜ì˜ í™•ì¥ ê°€ëŠ¥í•œ ë°±ì—”ë“œ

## ğŸ—ï¸ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­
- **CPU**: Intel/AMD 64ë¹„íŠ¸ í”„ë¡œì„¸ì„œ
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 8GB RAM (16GB ê¶Œì¥)
- **ì €ì¥ê³µê°„**: ìµœì†Œ 2GB ì—¬ìœ  ê³µê°„
- **NPU**: Snapdragon NPU (ì„ íƒì‚¬í•­, ì„±ëŠ¥ í–¥ìƒ)

### ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­
- **OS**: Windows 10/11 (64ë¹„íŠ¸)
- **Python**: 3.8 ì´ìƒ
- **ê°€ìƒí™˜ê²½**: conda ë˜ëŠ” venv ê¶Œì¥

## ğŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1. ì €ì¥ì†Œ í´ë¡ 
```bash
git clone https://github.com/your-username/zonemakerai.git
cd zonemakerai
```

### 2. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
```bash
# conda ì‚¬ìš©
conda create -n zonemakeraiconda python=3.9
conda activate zonemakeraiconda

# ë˜ëŠ” venv ì‚¬ìš©
python -m venv venv
venv\Scripts\activate  # Windows
```

### 3. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

### 4. í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸
```
zonemakerai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/           # FastAPI ë°±ì—”ë“œ
â”‚   â”œâ”€â”€ core/          # í•µì‹¬ ê¸°ëŠ¥ (ë°ì´í„° ìˆ˜ì§‘)
â”‚   â”œâ”€â”€ ml/            # ML íŒŒì´í”„ë¼ì¸
â”‚   â””â”€â”€ config/        # ì„¤ì • íŒŒì¼
â”œâ”€â”€ frontend/          # PySide6 GUI
â”œâ”€â”€ data/              # ë°ì´í„° ë° ëª¨ë¸ ì €ì¥
â”œâ”€â”€ logs/              # ë¡œê·¸ íŒŒì¼
â””â”€â”€ run.py             # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
```

## ğŸ§  ML íŒŒì´í”„ë¼ì¸ ìƒì„¸ ê°€ì´ë“œ

### ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸

#### êµ¬ì¡° ë° ì›ë¦¬
```
ì‚¬ìš©ì í™œë™ â†’ ìœˆë„ìš° ìƒíƒœ ëª¨ë‹ˆí„°ë§ â†’ 30ì´ˆ ì‹œí€€ìŠ¤ ìƒì„± â†’ ì‹¤ì‹œê°„ ë²„í¼ë§
```

#### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

**1. DataCollector í´ë˜ìŠ¤**
```python
from backend.core.data_collector import DataCollector

# ë°ì´í„° ìˆ˜ì§‘ê¸° ìƒì„±
collector = DataCollector()

# 30ì´ˆê°„ ì—°ì† ë°ì´í„° ìˆ˜ì§‘
activities = collector.collect_data_sample(duration_seconds=30)

# ë¹„ë™ê¸° ì—°ì† ìˆ˜ì§‘ (ì½œë°± ê¸°ë°˜)
def on_data_collected(samples):
    print(f"ìˆ˜ì§‘ëœ ìƒ˜í”Œ: {len(samples)}ê°œ")

collector.start_continuous_collection(30, callback=on_data_collected)
```

**2. ìˆ˜ì§‘ë˜ëŠ” ë°ì´í„° ìœ í˜•**
- **ìœˆë„ìš° ì •ë³´**: ì œëª©, í´ë˜ìŠ¤ëª…, í”„ë¡œì„¸ìŠ¤ëª…, ìœ„ì¹˜, í¬ê¸°, ìƒíƒœ
- **ì‚¬ìš©ì í™œë™**: ë§ˆìš°ìŠ¤ ìœ„ì¹˜, í‚¤ë³´ë“œ í™œë™, ìœˆë„ìš° ë³€í™”
- **ì‹œê³„ì—´ ë°ì´í„°**: 0.1ì´ˆë§ˆë‹¤ ìƒ˜í”Œë§í•˜ì—¬ 30ì´ˆ ì‹œí€€ìŠ¤ êµ¬ì„±

#### ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
```bash
# 30ì´ˆê°„ ë°ì´í„° ìˆ˜ì§‘
python run.py --mode data-collect --duration 30

# ê²°ê³¼: data/window_activity_data_[timestamp].json
```

### ğŸ¤– ML ëª¨ë¸ ì•„í‚¤í…ì²˜

#### ëª¨ë¸ êµ¬ì¡°
```
ì…ë ¥: 30ì´ˆ ìœˆë„ìš° ì‹œí€€ìŠ¤ + í™œë™ ì‹œí€€ìŠ¤
  â†“
WindowFeatureExtractor: ìœˆë„ìš° ì •ë³´ â†’ íŠ¹ì§• ë²¡í„°
  â†“
ActivityFeatureExtractor: ì‚¬ìš©ì í™œë™ â†’ íŠ¹ì§• ë²¡í„°
  â†“
Transformer Encoder: ì‹œí€€ìŠ¤ ì²˜ë¦¬
  â†“
ì¶œë ¥: ìœˆë„ìš°ë³„ ìœ„ì¹˜/í¬ê¸° + ì¡´ì¬ ì—¬ë¶€
```

#### ëª¨ë¸ ìƒì„± ë° ì‚¬ìš©
```python
from backend.ml.model import create_model, WindowArrangementPredictor

# ëª¨ë¸ ìƒì„±
model = create_model({
    'window_feature_dim': 128,
    'activity_feature_dim': 64,
    'hidden_dim': 256,
    'num_heads': 8,
    'num_layers': 6,
    'max_windows': 20
})

# ì˜ˆì¸¡ê¸° ìƒì„±
predictor = WindowArrangementPredictor("path/to/model.pth")

# ë‹¤ìŒ ìˆœê°„ ìœˆë„ìš° ë°°ì—´ ì˜ˆì¸¡
predicted_positions = predictor.predict_next_arrangement(
    window_sequence, activity_sequence
)
```

#### ëª¨ë¸ í›ˆë ¨
```bash
# ê¸°ë³¸ í›ˆë ¨ (50 ì—í¬í¬)
python run.py --mode train --epochs 50

# íŠ¹ì • ë°ì´í„° íŒŒì¼ë¡œ í›ˆë ¨
python run.py --mode train --data-file data/my_data.json --epochs 100

# ê²°ê³¼: data/models/best.pth, data/models/final.pth
```

### ğŸ”„ ì‹¤ì‹œê°„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸

#### ì¶”ë¡  ì—”ì§„ ë™ì‘ ì›ë¦¬
```
1. 30ì´ˆ ë°ì´í„° ë²„í¼ ìˆ˜ì§‘
2. ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ì˜ˆì¸¡ ìˆ˜í–‰
3. ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹¤ì œ ìœˆë„ìš°ì— ì ìš©
4. 1ì´ˆ í›„ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ë²„í¼ ì—…ë°ì´íŠ¸
5. ë°˜ë³µí•˜ì—¬ ì—°ì† ìµœì í™”
```

#### ì¶”ë¡  ì—”ì§„ ì‚¬ìš©ë²•
```python
from backend.ml.inference import RealTimeInferenceEngine

# ì¶”ë¡  ì—”ì§„ ìƒì„±
engine = RealTimeInferenceEngine(
    model_path="path/to/model.pth",
    prediction_interval=1.0  # 1ì´ˆë§ˆë‹¤ ì˜ˆì¸¡
)

# ì½œë°± ì„¤ì •
def on_prediction_complete(predictions, success):
    print(f"ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ ìœˆë„ìš°")

engine.set_callbacks(
    on_prediction_complete=on_prediction_complete
)

# ì¶”ë¡  ì‹œì‘
engine.start_inference()

# ìƒíƒœ í™•ì¸
status = engine.get_inference_status()
print(f"ë²„í¼ í¬ê¸°: {status['buffer_size']}/{status['buffer_max_size']}")

# ì¶”ë¡  ì¤‘ì§€
engine.stop_inference()
```

#### ì‹¤ì‹œê°„ ì¶”ë¡  ì‹¤í–‰
```bash
# 60ì´ˆê°„ ì‹¤ì‹œê°„ ì¶”ë¡ 
python run.py --mode inference --duration 60

# íŠ¹ì • ëª¨ë¸ë¡œ ì¶”ë¡ 
python run.py --mode inference --model-path data/models/best.pth --duration 120
```

### ğŸ¯ ì—°ì† í•™ìŠµ ì‹œìŠ¤í…œ

#### ContinuousLearningEngine
```python
from backend.ml.inference import ContinuousLearningEngine

# ì—°ì† í•™ìŠµ ì—”ì§„ ìƒì„±
learning_engine = ContinuousLearningEngine(
    model_path="path/to/model.pth",
    update_interval=300.0  # 5ë¶„ë§ˆë‹¤ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
)

# ì—°ì† í•™ìŠµ ì‹œì‘
learning_engine.start_continuous_learning()

# ìˆ˜ì§‘ëœ í•™ìŠµ ë°ì´í„° í™•ì¸
data_count = learning_engine.get_training_data_count()
print(f"ìˆ˜ì§‘ëœ í•™ìŠµ ë°ì´í„°: {data_count}ê°œ")

# í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°
learning_engine.export_training_data("continuous_learning_data.json")
```

### âš¡ NPU ìµœì í™” íŒŒì´í”„ë¼ì¸

#### NPU ë³€í™˜ ê³¼ì •
```
PyTorch ëª¨ë¸ â†’ ONNX ë³€í™˜ â†’ NPU ìµœì í™” â†’ Snapdragon NPU ì „ìš© ëª¨ë¸
```

#### NPU ë³€í™˜ ì‹¤í–‰
```bash
# NPU ë³€í™˜
python run.py --mode npu-convert

# íŠ¹ì • ëª¨ë¸ ë³€í™˜
python run.py --mode npu-convert --model-path data/models/best.pth

# ê²°ê³¼: data/models/npu_optimized.npu
```

#### NPU ë³€í™˜ê¸° ì‚¬ìš©ë²•
```python
from backend.ml.npu_converter import NPUConverter

# NPU ë³€í™˜ê¸° ìƒì„±
converter = NPUConverter("path/to/model.pth")

# NPU ë³€í™˜ ì‹¤í–‰
success = converter.convert_to_npu()

if success:
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    results = converter.benchmark_model()
    print(f"NPU ì„±ëŠ¥: {results}")
```

## ğŸ® ì‚¬ìš© ë°©ë²•

### 1. ë¹ ë¥¸ ì‹œì‘
```bash
# ì „ì²´ ì‹œìŠ¤í…œ ì‹¤í–‰ (ë°±ì—”ë“œ + í”„ë¡ íŠ¸ì—”ë“œ)
python run.py --mode all

# ë°±ì—”ë“œë§Œ ì‹¤í–‰
python run.py --mode backend

# í”„ë¡ íŠ¸ì—”ë“œë§Œ ì‹¤í–‰
python run.py --mode frontend
```

### 2. ë‹¨ê³„ë³„ ì‹¤í–‰

#### 1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘
```bash
# 30ì´ˆê°„ ì‚¬ìš©ì í™œë™ ë°ì´í„° ìˆ˜ì§‘
python run.py --mode data-collect --duration 30
```

#### 2ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨
```bash
# ìˆ˜ì§‘ëœ ë°ì´í„°ë¡œ ëª¨ë¸ í›ˆë ¨
python run.py --mode train --epochs 100
```

#### 3ë‹¨ê³„: ì‹¤ì‹œê°„ ì¶”ë¡ 
```bash
# í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì‹¤ì‹œê°„ ìœˆë„ìš° ë°°ì—´ ìµœì í™”
python run.py --mode inference --duration 300
```

#### 4ë‹¨ê³„: NPU ìµœì í™” (ì„ íƒì‚¬í•­)
```bash
# NPU ì „ìš© ëª¨ë¸ë¡œ ë³€í™˜
python run.py --mode npu-convert
```

### 3. ê³ ê¸‰ ì‚¬ìš©ë²•

#### ë°°ì¹˜ ì¶”ë¡ 
```python
from backend.ml.inference import BatchInferenceEngine

# ë°°ì¹˜ ì¶”ë¡  ì—”ì§„
batch_engine = BatchInferenceEngine("path/to/model.pth")

# ì—¬ëŸ¬ ë°ì´í„° íŒŒì¼ì— ëŒ€í•´ ë°°ì¹˜ ì˜ˆì¸¡
results = batch_engine.batch_predict(
    data_file="data/batch_data.json",
    output_file="results/batch_predictions.json"
)
```

#### ì»¤ìŠ¤í…€ ì„¤ì •
```python
from backend.config.settings import update_settings

# ì„¤ì • ì—…ë°ì´íŠ¸
update_settings({
    'ml': {
        'sequence_length': 45,  # 45ì´ˆ ì‹œí€€ìŠ¤
        'prediction_interval': 0.5,  # 0.5ì´ˆë§ˆë‹¤ ì˜ˆì¸¡
        'max_windows': 25
    }
})
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### 1. ëª¨ë¸ ê²½ëŸ‰í™”
- **ì–‘ìí™”**: int8 ì •ë°€ë„ë¡œ ëª¨ë¸ í¬ê¸° ê°ì†Œ
- **í”„ë£¨ë‹**: ë¶ˆí•„ìš”í•œ ê°€ì¤‘ì¹˜ ì œê±°
- **ì§€ì‹ ì¦ë¥˜**: ì‘ì€ ëª¨ë¸ë¡œ ì„±ëŠ¥ ìœ ì§€

### 2. ì¶”ë¡  ìµœì í™”
- **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ìœˆë„ìš° ë™ì‹œ ì˜ˆì¸¡
- **ë¹„ë™ê¸° ì²˜ë¦¬**: UI ë¸”ë¡œí‚¹ ë°©ì§€
- **ë©”ëª¨ë¦¬ ê´€ë¦¬**: íš¨ìœ¨ì ì¸ ë²„í¼ ê´€ë¦¬

### 3. NPU ìµœì í™”
- **ëª¨ë¸ ìœµí•©**: ì—°ì‚° ë ˆì´ì–´ ê²°í•©
- **ë©”ëª¨ë¦¬ ìµœì í™”**: NPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì‚¬ìš©
- **ë³‘ë ¬ ì²˜ë¦¬**: NPU ë³‘ë ¬ ì—°ì‚° í™œìš©

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1. ëª¨ë“ˆ import ì˜¤ë¥˜
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸
conda activate zonemakeraiconda

# ì˜ì¡´ì„± ì¬ì„¤ì¹˜
pip install -r requirements.txt
```

#### 2. Windows API ê¶Œí•œ ì˜¤ë¥˜
```bash
# ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰
# ë˜ëŠ” Windows Defender ì˜ˆì™¸ ì„¤ì •
```

#### 3. ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
python run.py --mode train --epochs 50  # ê¸°ë³¸ê°’ ì‚¬ìš©

# ì‹œí€€ìŠ¤ ê¸¸ì´ ì¤„ì´ê¸° (ì„¤ì • íŒŒì¼ì—ì„œ)
```

### ë””ë²„ê¹… íŒ

#### 1. ë¡œê·¸ ë ˆë²¨ ì¡°ì •
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

#### 2. ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
```bash
# ì§§ì€ ì‹œê°„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
python run.py --mode data-collect --duration 5
```

#### 3. ëª¨ë¸ í…ŒìŠ¤íŠ¸
```python
# ê°„ë‹¨í•œ ì…ë ¥ìœ¼ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸
python backend/ml/model.py
```

## ğŸ”§ ê°œë°œ ê°€ì´ë“œ

### 1. ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€
```python
# ìƒˆë¡œìš´ íŠ¹ì§• ì¶”ì¶œê¸° ì¶”ê°€
class CustomFeatureExtractor(nn.Module):
    def __init__(self, feature_dim):
        super().__init__()
        # êµ¬í˜„...
    
    def forward(self, data):
        # êµ¬í˜„...
        return features
```

### 2. ëª¨ë¸ ì•„í‚¤í…ì²˜ ìˆ˜ì •
```python
# ëª¨ë¸ ì„¤ì • ë³€ê²½
config = {
    'window_feature_dim': 256,  # ì¦ê°€
    'hidden_dim': 512,          # ì¦ê°€
    'num_layers': 8             # ì¦ê°€
}

model = create_model(config)
```

### 3. ìƒˆë¡œìš´ ì¶”ë¡  ë°©ì‹ ì¶”ê°€
```python
# ì»¤ìŠ¤í…€ ì¶”ë¡  ì—”ì§„
class CustomInferenceEngine(RealTimeInferenceEngine):
    def _perform_prediction(self):
        # ì»¤ìŠ¤í…€ ì˜ˆì¸¡ ë¡œì§
        pass
```

## ğŸ“š API ì°¸ì¡°

### í•µì‹¬ í´ë˜ìŠ¤

#### DataCollector
- `collect_data_sample(duration)`: ì§€ì •ëœ ì‹œê°„ ë™ì•ˆ ë°ì´í„° ìˆ˜ì§‘
- `start_continuous_collection(duration, callback)`: ì—°ì† ë°ì´í„° ìˆ˜ì§‘
- `save_data(activities, filename)`: ë°ì´í„° ì €ì¥

#### RealTimeWindowPredictor
- `predict_next_arrangement(window_seq, activity_seq)`: ë‹¤ìŒ ìˆœê°„ ì˜ˆì¸¡
- `apply_prediction(window_handles, positions)`: ì˜ˆì¸¡ ê²°ê³¼ ì ìš©

#### RealTimeInferenceEngine
- `start_inference()`: ì¶”ë¡  ì‹œì‘
- `stop_inference()`: ì¶”ë¡  ì¤‘ì§€
- `get_inference_status()`: ìƒíƒœ ì •ë³´ ë°˜í™˜

#### ModelTrainer
- `prepare_training_data(data_file, ...)`: í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
- `train(train_loader, val_loader, ...)`: ëª¨ë¸ í›ˆë ¨
- `export_to_onnx(save_path)`: ONNX ëª¨ë¸ ë‚´ë³´ë‚´ê¸°

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ“ ì§€ì›

- **Issues**: GitHub Issues ì‚¬ìš©
- **Discussions**: GitHub Discussions ì°¸ì—¬
- **Wiki**: í”„ë¡œì íŠ¸ Wiki ì°¸ì¡°

## ğŸ“ ë³€ê²½ ì´ë ¥

### v1.0.0 (2024-01-XX)
- ì´ˆê¸° ML íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- ì‹¤ì‹œê°„ ì—°ì† ì˜ˆì¸¡ ì‹œìŠ¤í…œ
- NPU ìµœì í™” ì§€ì›
- PySide6 ê¸°ë°˜ GUI
- FastAPI ë°±ì—”ë“œ

---

**Zonemaker AI** - AIë¡œ ìœˆë„ìš°ë¥¼ ë” ìŠ¤ë§ˆíŠ¸í•˜ê²Œ!